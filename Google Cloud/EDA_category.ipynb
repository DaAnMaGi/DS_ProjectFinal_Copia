{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tratamiento de columna category dataset Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cargar todos los archivos JSON en la carpeta \n",
    "\n",
    "# Lista para almacenar los datos de los archivos JSON\n",
    "data_list = []\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos JSON\n",
    "folder_path = './dataset/google/metadata-sitios2'\n",
    "\n",
    "# Iterar sobre todos los archivos en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Verificar si el archivo es un archivo JSON\n",
    "    if filename.endswith('.json'):\n",
    "        # Construir la ruta completa del archivo\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        # Leer el archivo JSON línea por línea\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                # Cargar cada línea como un objeto JSON y agregarlo a la lista\n",
    "                data = json.loads(line)\n",
    "                data_list.append(data)\n",
    "\n",
    "# Crear el DataFrame a partir de la lista de datos\n",
    "df_g_sitios = pd.DataFrame(data_list)\n",
    "\n",
    "print(df_g_sitios.shape)\n",
    "print(df_g_sitios.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para generar una fila diferente por cada elemento en la lista de category\n",
    "# Asegurarse de que las listas están manejadas correctamente y no hay valores NaN\n",
    "df_g_sitios['category_explode'] = df_g_sitios['category'].apply(lambda x: x if isinstance(x, list) else [x] if pd.notna(x) else [])\n",
    "\n",
    "# Expandir las listas en filas individuales\n",
    "df_categories_expanded = df_g_sitios.explode('category_explode')\n",
    "\n",
    "# Calcular el número de valores únicos\n",
    "num_categorias_unicas = df_categories_expanded['category_explode'].nunique()\n",
    "print(f'Número de categorías únicas: {num_categorias_unicas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las filas que contienen la palabra 'restaurant' (case insensitive)\n",
    "df_restaurant_categories = df_categories_expanded[df_categories_expanded['category_explode'].str.contains('restaurant', case=False, na=False)]\n",
    "\n",
    "# Contar la frecuencia de cada categoría\n",
    "print(df_restaurant_categories['category_explode'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el array numpy en un DataFrame de pandas\n",
    "unique_values = pd.DataFrame(df_restaurant_categories['category_explode'].unique())\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "unique_values.to_csv('valores_unicos_categories_google.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tratamiento de columna category dataset YELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo pickle en un DataFrame\n",
    "dfy_business = pd.read_pickle(\"./dataset/yelp/business.pkl\")\n",
    "\n",
    "print(dfy_business.shape)\n",
    "\n",
    "print(dfy_business.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas duplicadas seleccionando solo las primeras 14 columnas\n",
    "dfy_business = dfy_business.iloc[:, :14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para generar una fila diferente por cada elemento en la lista de category\n",
    "# Asegurarse de que las listas están manejadas correctamente y no hay valores NaN\n",
    "dfy_business['categories_explode'] = dfy_business['categories'].apply(lambda x: x if isinstance(x, list) else [x] if pd.notna(x) else [])\n",
    "\n",
    "# Expandir las listas en filas individuales\n",
    "df_categories_expanded = dfy_business.explode('categories_explode')\n",
    "\n",
    "# Calcular el número de valores únicos\n",
    "num_categorias_unicas = df_categories_expanded['categories_explode'].nunique()\n",
    "print(f'Número de categorías únicas: {num_categorias_unicas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las filas que contienen la palabra 'restaurant' (case insensitive)\n",
    "dfy_restaurant_categories = dfy_business[dfy_business['categories'].str.contains('restaurant', case=False, na=False)]\n",
    "\n",
    "# Contar la frecuencia de cada categoría\n",
    "print(dfy_restaurant_categories['categories'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV con nombres estándar de categorias provenientes de google\n",
    "df_standard_categories = pd.read_csv('valores_unicos_categories_google.csv')\n",
    "\n",
    "standard_categories = df_standard_categories['categories_standard'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para quitar la palabra restaurants de la columna categories para mejorar la clasificacion\n",
    "# Definir una función para limpiar la categoría\n",
    "def limpiar_categoria(categoria):\n",
    "    if categoria.strip().lower() == 'restaurants':\n",
    "        return categoria\n",
    "    # Eliminar todas las apariciones de la palabra 'restaurants'\n",
    "    cleaned_category = re.sub(r'\\brestaurants?\\b', '', categoria, flags=re.IGNORECASE).strip()\n",
    "    # Eliminar comas innecesarias y espacios adicionales\n",
    "    cleaned_category = re.sub(r'\\s*,\\s*', ', ', cleaned_category)\n",
    "    cleaned_category = re.sub(r',\\s*$', '', cleaned_category)\n",
    "    return cleaned_category\n",
    "\n",
    "# Aplicar la función a la columna 'categories' para crear una nueva columna 'categories_clean'\n",
    "dfy_restaurant_categories['categories_clean'] = dfy_restaurant_categories['categories'].apply(limpiar_categoria)\n",
    "\n",
    "# Mostrar algunos resultados para verificar\n",
    "print(dfy_restaurant_categories[['categories', 'categories_clean']].head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para quitar la palabra 'food' de la columna categories para mejorar la clasificacion\n",
    "# Definir una función para limpiar la categoría\n",
    "def limpiar_categoria(categoria):\n",
    "    if categoria.strip().lower() == 'food':\n",
    "        return categoria\n",
    "    # Eliminar todas las apariciones de la palabra 'food'\n",
    "    cleaned_category = re.sub(r'\\bfood?\\b', '', categoria, flags=re.IGNORECASE).strip()\n",
    "    # Eliminar comas innecesarias y espacios adicionales\n",
    "    cleaned_category = re.sub(r'\\s*,\\s*', ', ', cleaned_category)\n",
    "    cleaned_category = re.sub(r',\\s*$', '', cleaned_category)\n",
    "    return cleaned_category\n",
    "\n",
    "# Aplicar la función a la columna 'categories' para crear una nueva columna 'categories_clean'\n",
    "dfy_restaurant_categories['categories_clean'] = dfy_restaurant_categories['categories_clean'].apply(limpiar_categoria)\n",
    "\n",
    "# Mostrar algunos resultados para verificar\n",
    "print(dfy_restaurant_categories[['categories', 'categories_clean']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función para encontrar la categoría estándar más similar:\n",
    "def find_closest_category(category, standard_categories):\n",
    "    # Encontrar la categoría estándar más similar\n",
    "    closest_match, score = process.extractOne(category, standard_categories)\n",
    "    return closest_match, score\n",
    "\n",
    "# Aplicar la función al DataFrame df_restaurant_categories:\n",
    "dfy_restaurant_categories[['categories_standard', 'score']] = dfy_restaurant_categories['categories_clean'].apply(lambda x: pd.Series(find_closest_category(x, standard_categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfy_restaurant_categories['categories_standard'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el dataframe en disco en un archivo con formato parquet\n",
    "dfy_restaurant_categories.to_parquet('dfy_restaurant_categories.parquet')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
