{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from google.cloud import storage\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_atributos = pd.read_parquet(\"../Data/dfgy_attributes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RestaurantsDelivery', 'OutdoorSeating',\n",
       "       'BusinessAcceptsCreditCards', 'BusinessParking', 'BikeParking',\n",
       "       'RestaurantsPriceRange2', 'RestaurantsTakeOut',\n",
       "       'ByAppointmentOnly', 'WiFi', 'Alcohol', 'Caters',\n",
       "       'WheelchairAccessible', 'GoodForKids', 'RestaurantsAttire',\n",
       "       'RestaurantsReservations', 'Ambience', 'CoatCheck', 'DogsAllowed',\n",
       "       'RestaurantsTableService', 'RestaurantsGoodForGroups', 'HasTV',\n",
       "       'HappyHour', 'DriveThru', 'NoiseLevel', 'GoodForMeal',\n",
       "       'BusinessAcceptsBitcoin', 'Smoking', 'Music', 'GoodForDancing',\n",
       "       'BestNights', 'BYOB', 'Corkage', 'BYOBCorkage', 'AcceptsInsurance',\n",
       "       'RestaurantsCounterService', 'Open24Hours', 'AgesAllowed',\n",
       "       'DietaryRestrictions', 'HairSpecializesIn', 'Good for kids',\n",
       "       'Restroom', 'Bar onsite', 'Wi-Fi', 'Gender-neutral restroom',\n",
       "       'Public restroom', 'High chairs', 'Restaurant', 'Golf course',\n",
       "       'Mechanic', 'Air conditioning', 'Bar on site', 'Toilets',\n",
       "       'Gender-neutral toilets', 'Public toilet', 'Baggage storage',\n",
       "       'Swimming pool', 'All-inclusive', 'Stadium seating',\n",
       "       'Wheelchair accessible entrance', 'Wheelchair accessible elevator',\n",
       "       'Wheelchair accessible seating', 'Wheelchair accessible restroom',\n",
       "       'Wheelchair accessible parking lot', 'Assisted listening devices',\n",
       "       'Wheelchair-accessible car park', 'Wheelchair-accessible entrance',\n",
       "       'Wheelchair-accessible toilet', 'Wheelchair-accessible seating',\n",
       "       'Wheelchair-accessible lift'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se observan los atributos.\n",
    "sites_atributos[\"attributes\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se seleccionan los atributos que van a ser unificados o corregidos a través de un diccionario de mapeo.\n",
    "reemplazo_atributos = {\n",
    "    \"Accessible entrance\":['Wheelchair accessible entrance','Wheelchair-accessible entrance',\"WheelchairAccessible\"],\n",
    "    \"Accessible elevator\":[\"Wheelchair accessible elevator\",\"Wheelchair-accessible lift\"],\n",
    "    \"Accessible seating\":['Wheelchair accessible seating','Wheelchair-accessible seating'],\n",
    "    \"Accessible restroom\":['Wheelchair accessible restroom','Wheelchair-accessible toilet'],\n",
    "    \"Accessible parking\":['Wheelchair accessible parking lot','Wheelchair-accessible car park'],\n",
    "    \"Wifi\":['WiFi','Wi-Fi'],\n",
    "    \"Delivery&TakeOut\":[\"RestaurantsDelivery\",'RestaurantsTakeOut'],\n",
    "    \"Outdoor Seating\":['OutdoorSeating'],\n",
    "    \"Accepts Cards\":['BusinessAcceptsCreditCards',\"BusinessAcceptsBitcoin\"],\n",
    "    \"Parking\":[\"BusinessParking\",'BikeParking'],\n",
    "    \"Appointment Only\":['ByAppointmentOnly'],\n",
    "    \"Reservations\":['RestaurantsReservations'],\n",
    "    \"HappyHour\":['HappyHour','BestNights'],\n",
    "    \"BYOB\":['BYOB', 'Corkage', 'BYOBCorkage'],\n",
    "    'Good for kids':['Good for kids','GoodForKids'],\n",
    "    \"Sells Alcohol\":['Alcohol','Bar onsite','Bar on site'],\n",
    "    \"Restroom\":['Restroom','Gender-neutral restroom','Public restroom','Toilets','Gender-neutral toilets','Public toilet'],\n",
    "    'Baggage storage':['Baggage storage','CoatCheck']\n",
    "\n",
    "}\n",
    "\n",
    "# Se seleccionan los atributos que no proporcionan información útil para el proceso de análisis.\n",
    "eliminar_atributos = ['Caters','RestaurantsPriceRange2','Ambience','RestaurantsTableService','NoiseLevel',\n",
    "                      'Music','AcceptsInsurance','AgesAllowed','HairSpecializesIn','High chairs', 'Restaurant','Golf course',\n",
    "                      'Mechanic','Swimming pool', 'All-inclusive', 'Stadium seating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se invierte el diccionario de mapeo para usarlo en el método \"replace\".\n",
    "reverse_mapping = {v: k for k, values in reemplazo_atributos.items() for v in values}\n",
    "\n",
    "# Se reeemplazan los valores en la columna 'atributos' usando el diccionario invertido\n",
    "sites_atributos['attributes'] = sites_atributos['attributes'].replace(reverse_mapping)\n",
    "\n",
    "# Se filtra y eliminan las filas que contienen atributos en eliminar_atributos\n",
    "sites_atributos = sites_atributos[~sites_atributos['attributes'].str.contains('|'.join(eliminar_atributos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Delivery&TakeOut', 'Outdoor Seating', 'Accepts Cards', 'Parking',\n",
       "       'Appointment Only', 'Wifi', 'Sells Alcohol', 'Accessible entrance',\n",
       "       'Good for kids', 'Reservations', 'Baggage storage', 'DogsAllowed',\n",
       "       'HasTV', 'HappyHour', 'DriveThru', 'GoodForMeal', 'Smoking',\n",
       "       'GoodForDancing', 'BYOB', 'Open24Hours', 'DietaryRestrictions',\n",
       "       'Restroom', 'Air conditioning', 'Accessible elevator',\n",
       "       'Accessible seating', 'Accessible restroom', 'Accessible parking',\n",
       "       'Assisted listening devices'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se observan las categorías limpias.\n",
    "sites_atributos[\"attributes\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subida del dataframe a Google Cloud \n",
    "\n",
    "# Configura tus credenciales de Google Cloud\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'\n",
    "\n",
    "# Función que sube el archivo a Google Cloud Storage\n",
    "def upload_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Sube un archivo a un bucket de Google Cloud Storage.\"\"\"\n",
    "    # Inicializa el cliente de GCS\n",
    "    storage_client = storage.Client()\n",
    "    # Obtén el bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    # Crea un blob en el bucket\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    # Sube el archivo al blob\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    print(f\"Archivo {source_file_name} subido a {destination_blob_name}.\")\n",
    "\n",
    "# Función que guarda el dataframe en un archivo temporal de parquet y lo sube\n",
    "def dataframe_to_parquet_and_upload(df, bucket_name, destination_blob_name):\n",
    "    # Guarda el DataFrame como archivo Parquet\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, 'temp.parquet')\n",
    "\n",
    "    # Sube el archivo Parquet a Google Cloud Storage\n",
    "    upload_to_gcs(bucket_name, 'temp.parquet', destination_blob_name)\n",
    "\n",
    "    # Elimina el archivo temporal\n",
    "    os.remove('temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo temp.parquet subido a dfgy_attributes.parquet.\n"
     ]
    }
   ],
   "source": [
    "# Se sube el dataframe de atributos\n",
    "\n",
    "# Nombre del bucket de GCS y del archivo destino\n",
    "bucket_name = 'scripts-python-proyecto-henry'\n",
    "destination_blob_name = 'dfgy_attributes.parquet'\n",
    "\n",
    "dataframe_to_parquet_and_upload(sites_atributos,bucket_name,destination_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba Dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para almacenar los dataframes de todos los estados\n",
    "dataframes = []\n",
    "\n",
    "# Función para procesar cada estado y ruta\n",
    "def procesar_archivos_json(state, ruta_directorio, chunksize=10000):\n",
    "    for filename in os.listdir(ruta_directorio):\n",
    "        if filename.endswith('.json'):\n",
    "            try:\n",
    "                filepath = os.path.join(ruta_directorio, filename)\n",
    "                with pd.read_json(filepath, lines=True, chunksize=chunksize) as reader:\n",
    "                    for chunk in reader:\n",
    "                        chunk['state'] = state\n",
    "                        dataframes.append(chunk)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar el archivo {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de estados y rutas\n",
    "estados_ruta = {\n",
    "    \"AL\": \"../Data/Google/reviews-estados/review-Alabama/review-Alabama\",\n",
    "    'AK':'../Data/Google/reviews-estados/review-Alaska/review-Alaska',\n",
    "    'AZ':'../Data/Google/reviews-estados/review-Arizona/review-Arizona',\n",
    "    'AR':'../Data/Google/reviews-estados/review-Arkansas/review-Arkansas',\n",
    "    'CA':'../Data/Google/reviews-estados/review-California/review-California',\n",
    "    'CO':'../Data/Google/reviews-estados/review-Colorado/review-Colorado',\n",
    "    'CT':'../Data/Google/reviews-estados/review-Connecticut/review-Connecticut',\n",
    "    'DE':\"../Data/Google/reviews-estados/review-Delaware/review-Delaware\",\n",
    "    'District_of_Columbia':\"../Data/Google/reviews-estados/review-District_of_Columbia\",\n",
    "    'FL':\"../Data/Google/reviews-estados/review-Florida/review-Florida\",\n",
    "    'GA':\"../Data/Google/reviews-estados/review-Georgia/review-Georgia\",\n",
    "    'HI':\"../Data/Google/reviews-estados/review-Hawaii/review-Hawaii\",\n",
    "    'ID':\"../Data/Google/reviews-estados/review-Idaho/review-Idaho\",\n",
    "    'IL':\"../Data/Google/reviews-estados/review-Illinois/review-Illinois\",\n",
    "    'IN':\"../Data/Google/reviews-estados/review-Indiana/review-Indiana\",\n",
    "    'IA':\"../Data/Google/reviews-estados/review-Iowa/review-Iowa\",\n",
    "    'KS':\"../Data/Google/reviews-estados/review-Kansas/review-Kansas\",\n",
    "    'KY':\"../Data/Google/reviews-estados/review-Kentucky/review-Kentucky\",\n",
    "    'LA':\"../Data/Google/reviews-estados/review-Louisiana/review-Louisiana\",\n",
    "    'ME':\"../Data/Google/reviews-estados/review-Maine/review-Maine\",\n",
    "    'MD':\"../Data/Google/reviews-estados/review-Maryland/review-Maryland\",\n",
    "    'MA':\"../Data/Google/reviews-estados/review-Massachusetts/review-Massachusetts\",\n",
    "    'MI':\"../Data/Google/reviews-estados/review-Michigan/review-Michigan\",\n",
    "    'MN':\"../Data/Google/reviews-estados/review-Minnesota/review-Minnesota\",\n",
    "    'MS':\"../Data/Google/reviews-estados/review-Mississippi/review-Mississippi\",\n",
    "    'MO':\"../Data/Google/reviews-estados/review-Missouri/review-Missouri\",\n",
    "    'MT':\"../Data/Google/reviews-estados/review-Montana/review-Montana\",\n",
    "    'NE':\"../Data/Google/reviews-estados/review-Nebraska/review-Nebraska\",\n",
    "    'NV':\"../Data/Google/reviews-estados/review-Nevada/review-Nevada\",\n",
    "    'NH':\"../Data/Google/reviews-estados/review-New_Hampshire/review-New_Hampshire\",\n",
    "    'NJ':\"../Data/Google/reviews-estados/review-New_Jersey/review-New_Jersey\",\n",
    "    'NM':\"../Data/Google/reviews-estados/review-New_Mexico/review-New_Mexico\",\n",
    "    'NY':\"../Data/Google/reviews-estados/review-New_York/review-New_York\",\n",
    "    'NC':\"../Data/Google/reviews-estados/review-North_Carolina/review-North_Carolina\",\n",
    "    'ND':\"../Data/Google/reviews-estados/review-North_Dakota/review-North_Dakota\",\n",
    "    'OH':\"../Data/Google/reviews-estados/review-Ohio/review-Ohio\",\n",
    "    'OK':\"../Data/Google/reviews-estados/review-Oklahoma/review-Oklahoma\",\n",
    "    'OR':\"../Data/Google/reviews-estados/review-Oregon/review-Oregon\",\n",
    "    'PA':\"../Data/Google/reviews-estados/review-Pennsylvania/review-Pennsylvania\",\n",
    "    'RI':\"../Data/Google/reviews-estados/review-Rhode_Island/review-Rhode_Island\",\n",
    "    'SC':\"../Data/Google/reviews-estados/review-South_Carolina/review-South_Carolina\",\n",
    "    'SD':\"../Data/Google/reviews-estados/review-South_Dakota/review-South_Dakota\",\n",
    "    'TN':\"../Data/Google/reviews-estados/review-Tennessee/review-Tennessee\",\n",
    "    'TX':\"../Data/Google/reviews-estados/review-Texas/review-Texas\",\n",
    "    'UT':\"../Data/Google/reviews-estados/review-Utah/review-Utah\",\n",
    "    'VT':\"../Data/Google/reviews-estados/review-Vermont/review-Vermont\",\n",
    "    'VA':\"../Data/Google/reviews-estados/review-Virginia/review-Virginia\",\n",
    "    'WA':\"../Data/Google/reviews-estados/review-Washington/review-Washington\",\n",
    "    'WV':\"../Data/Google/reviews-estados/review-West_Virginia/review-West_Virginia\",\n",
    "    'WI':\"../Data/Google/reviews-estados/review-Wisconsin/review-Wisconsin\",\n",
    "    'WY':\"../Data/Google/reviews-estados/review-Wyoming/review-Wyoming\"\n",
    "}\n",
    "\n",
    "\n",
    "# Iterar sobre el diccionario y procesar los archivos\n",
    "for state, ruta_directorio in estados_ruta.items():\n",
    "    procesar_archivos_json(state, ruta_directorio)\n",
    "\n",
    "# Concatenar todos los dataframes en uno solo\n",
    "dfg_reviews = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Mostrar el dataframe final\n",
    "print(dfg_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tablas BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un cliente de BigQuery\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets en el proyecto proyecto-nuevo-423502:\n",
      "\tData_Henry_Final\n"
     ]
    }
   ],
   "source": [
    "datasets = list(client.list_datasets())\n",
    "if datasets:\n",
    "    print(\"Datasets en el proyecto {}:\".format(client.project))\n",
    "    for dataset in datasets:\n",
    "        print(\"\\t{}\".format(dataset.dataset_id))\n",
    "else:\n",
    "    print(\"{} no tiene conjuntos de datos.\".format(client.project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(query)  \u001b[38;5;66;03m# Ejecutar la consulta\u001b[39;00m\n\u001b[0;32m     38\u001b[0m results \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m---> 39\u001b[0m usuarios \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Reviews\u001b[39;00m\n\u001b[0;32m     43\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124m    SELECT *\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124m    FROM `proyecto-nuevo-423502.Data_Henry_Final.reviews`\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:2379\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[0;32m   2376\u001b[0m     create_bqstorage_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   2377\u001b[0m     bqstorage_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2379\u001b[0m record_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arrow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2385\u001b[0m \u001b[38;5;66;03m# Default date dtype is `db_dtypes.DateDtype()` that could cause out of bounds error,\u001b[39;00m\n\u001b[0;32m   2386\u001b[0m \u001b[38;5;66;03m# when pyarrow converts date values to nanosecond precision. To avoid the error, we\u001b[39;00m\n\u001b[0;32m   2387\u001b[0m \u001b[38;5;66;03m# set the date_as_object parameter to True, if necessary.\u001b[39;00m\n\u001b[0;32m   2388\u001b[0m date_as_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1946\u001b[0m, in \u001b[0;36mRowIterator.to_arrow\u001b[1;34m(self, progress_bar_type, bqstorage_client, create_bqstorage_client)\u001b[0m\n\u001b[0;32m   1941\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[0;32m   1942\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_rows, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1943\u001b[0m )\n\u001b[0;32m   1945\u001b[0m record_batches \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1946\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arrow_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\n\u001b[0;32m   1948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecord_batches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# In some cases, the number of total rows is not populated\u001b[39;49;00m\n\u001b[0;32m   1953\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# until the first page of rows is fetched. Update the\u001b[39;49;00m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# progress bar's total to keep an accurate count.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1809\u001b[0m, in \u001b[0;36mRowIterator._to_page_iterable\u001b[1;34m(self, bqstorage_download, tabledata_list_download, bqstorage_client)\u001b[0m\n\u001b[0;32m   1802\u001b[0m     bqstorage_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1804\u001b[0m result_pages \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1805\u001b[0m     bqstorage_download()\n\u001b[0;32m   1806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bqstorage_client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m tabledata_list_download()\n\u001b[0;32m   1808\u001b[0m )\n\u001b[1;32m-> 1809\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m result_pages\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:731\u001b[0m, in \u001b[0;36mdownload_arrow_row_iterator\u001b[1;34m(pages, bq_schema)\u001b[0m\n\u001b[0;32m    728\u001b[0m arrow_types \u001b[38;5;241m=\u001b[39m [bq_to_arrow_data_type(field) \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m bq_schema]\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pages:\n\u001b[1;32m--> 731\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_row_iterator_page_to_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrow_types\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_pandas_helpers.py:704\u001b[0m, in \u001b[0;36m_row_iterator_page_to_arrow\u001b[1;34m(page, column_names, arrow_types)\u001b[0m\n\u001b[0;32m    702\u001b[0m arrays \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_index, arrow_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrow_types):\n\u001b[1;32m--> 704\u001b[0m     arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_columns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(column_names, pyarrow\u001b[38;5;241m.\u001b[39mSchema):\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pyarrow\u001b[38;5;241m.\u001b[39mRecordBatch\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mcolumn_names)\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\array.pxi:355\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\array.pxi:42\u001b[0m, in \u001b[0;36mpyarrow.lib._sequence_to_array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\error.pxi:88\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:3254\u001b[0m, in \u001b[0;36m_row_iterator_page_columns.<locals>.get_column_data\u001b[1;34m(field_index, field)\u001b[0m\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_column_data\u001b[39m(field_index, field):\n\u001b[0;32m   3253\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[1;32m-> 3254\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_field_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_helpers.py:389\u001b[0m, in \u001b[0;36m_field_from_json\u001b[1;34m(resource, field)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [converter(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m], field) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m resource]\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\_helpers.py:270\u001b[0m, in \u001b[0;36m_datetime_from_json\u001b[1;34m(value, field)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mstrptime(value, _RFC3339_MICROS_NO_ZULU)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;66;03m# YYYY-MM-DDTHH:MM:SS\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_RFC3339_NO_FRACTION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\_strptime.py:554\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    552\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 554\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    555\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    556\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\_strptime.py:351\u001b[0m, in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    349\u001b[0m weekday \u001b[38;5;241m=\u001b[39m julian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    350\u001b[0m found_dict \u001b[38;5;241m=\u001b[39m found\u001b[38;5;241m.\u001b[39mgroupdict()\n\u001b[1;32m--> 351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group_key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfound_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;66;03m# Directives not explicitly handled below:\u001b[39;00m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;66;03m#   c, x, X\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m#      handled by making out of other directives\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m#   U, W\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m#      worthless without day of the week\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m group_key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    358\u001b[0m         year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(found_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Atributos\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `proyecto-nuevo-423502.Data_Henry_Final.atributos`\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)  # Ejecutar la consulta\n",
    "results = query_job.result()\n",
    "atributos = results.to_dataframe()\n",
    "\n",
    "# Categorias\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `proyecto-nuevo-423502.Data_Henry_Final.categorias`\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)  # Ejecutar la consulta\n",
    "results = query_job.result()\n",
    "categorias = results.to_dataframe()\n",
    "\n",
    "# Restaurantes\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `proyecto-nuevo-423502.Data_Henry_Final.restaurantes`\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)  # Ejecutar la consulta\n",
    "results = query_job.result()\n",
    "restaurantes = results.to_dataframe()\n",
    "\n",
    "# Usuarios\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `proyecto-nuevo-423502.Data_Henry_Final.usuarios`\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)  # Ejecutar la consulta\n",
    "results = query_job.result()\n",
    "usuarios = results.to_dataframe()\n",
    "\n",
    "\n",
    "# Reviews\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `proyecto-nuevo-423502.Data_Henry_Final.reviews`\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)  # Ejecutar la consulta\n",
    "results = query_job.result()\n",
    "reviews = results.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset reviews final con texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import random\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una función para subir los dataframes preprocesados a Google Cloud Storage\n",
    "\n",
    "# Configura tus credenciales de Google Cloud\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'path/to/your/credentials.json'\n",
    "\n",
    "# Función que sube el archivo a Google Cloud Storage\n",
    "def upload_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Sube un archivo a un bucket de Google Cloud Storage.\"\"\"\n",
    "    # Inicializa el cliente de GCS\n",
    "    storage_client = storage.Client()\n",
    "    # Obtén el bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    # Crea un blob en el bucket\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    # Sube el archivo al blob\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    print(f\"Archivo {source_file_name} subido a {destination_blob_name}.\")\n",
    "\n",
    "# Función que guarda el dataframe en un archivo temporal de parquet y lo sube\n",
    "def dataframe_to_parquet_and_upload(df, bucket_name, destination_blob_name):\n",
    "    # Guarda el DataFrame como archivo Parquet\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, 'temp.parquet')\n",
    "\n",
    "    # Sube el archivo Parquet a Google Cloud Storage\n",
    "    upload_to_gcs(bucket_name, 'temp.parquet', destination_blob_name)\n",
    "\n",
    "    # Elimina el archivo temporal\n",
    "    os.remove('temp.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre del bucket de GCS\n",
    "bucket_name = 'archivos-preprocesados-henry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m sample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(num_rows \u001b[38;5;241m*\u001b[39m sample_fraction)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Leer el dataset completo\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Tomar una muestra aleatoria del 30% de los datos\u001b[39;00m\n\u001b[0;32m     18\u001b[0m sample_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39msample_fraction, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[1;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    268\u001b[0m     path,\n\u001b[0;32m    269\u001b[0m     filesystem,\n\u001b[0;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m )\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1811\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[0;32m   1799\u001b[0m     \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[0;32m   1800\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[0;32m   1801\u001b[0m         source, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[0;32m   1802\u001b[0m         memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1808\u001b[0m         page_checksum_verification\u001b[38;5;241m=\u001b[39mpage_checksum_verification,\n\u001b[0;32m   1809\u001b[0m     )\n\u001b[1;32m-> 1811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m                    \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmon2\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyarrow\\parquet\\core.py:1454\u001b[0m, in \u001b[0;36mParquetDataset.read\u001b[1;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[0;32m   1446\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1447\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[0;32m   1448\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   1449\u001b[0m         ]\n\u001b[0;32m   1450\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1451\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[0;32m   1452\u001b[0m         )\n\u001b[1;32m-> 1454\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Definir el porcentaje de muestra que deseas\n",
    "sample_fraction = 0.10\n",
    "\n",
    "# Leer el archivo parquet\n",
    "parquet_file = \"../Data/dfgy_reviews_text.parquet\"\n",
    "\n",
    "# Leer metadatos del archivo parquet\n",
    "parquet_metadata = pq.ParquetFile(parquet_file).metadata\n",
    "num_rows = parquet_metadata.num_rows\n",
    "\n",
    "# Calcular el número de filas a tomar en la muestra\n",
    "sample_size = int(num_rows * sample_fraction)\n",
    "\n",
    "# Leer el dataset completo\n",
    "df = pd.read_parquet(parquet_file)\n",
    "\n",
    "# Tomar una muestra aleatoria del 30% de los datos\n",
    "sample_df = df.sample(frac=sample_fraction, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
